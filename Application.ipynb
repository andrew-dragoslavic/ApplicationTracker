{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"11xJa5V5F167jkryR4g2zwR-nUKAze7aH","authorship_tag":"ABX9TyPW0ucBpPk/5mmN/Kgvn1nI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import userdata\n","\n","# Install Git\n","!apt-get install git\n","\n","# Configure Git\n","gmail = userdata.get('GITHUB_EMAIL')\n","!git config --global user.name \"andrew-dragoslavic\"\n","!git config --global user.email {gmail}\n","\n","# Clone the existing repo (instead of initializing a new one)\n","repo_name = \"ApplicationTracker\"\n","username = \"andrew-dragoslavic\"\n","!git clone https://github.com/{username}/{repo_name}.git\n","%cd {repo_name}\n","\n","# Copy the updated notebook\n","notebook_name = \"Application.ipynb\"\n","!cp \"/content/drive/My Drive/Colab Notebooks/{notebook_name}\" .\n","\n","# Add and commit\n","!git add {notebook_name}\n","!git commit -m \"Update: Add latest application tracking notebook\"\n","\n","# Push using PAT\n","\n","token = userdata.get('GITHUB_TOKEN')\n","!git push https://{username}:{token}@github.com/{username}/{repo_name}.git master"],"metadata":{"id":"Bl9fcHF43sBj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1742581742348,"user_tz":240,"elapsed":4197,"user":{"displayName":"Andrew Dragoslavic","userId":"16159173524798405463"}},"outputId":"36c2bf4c-d70b-4f1e-ca59-8103b95450b1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git is already the newest version (1:2.34.1-1ubuntu1.12).\n","0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n","/content/ApplicationTracker/ApplicationTracker/ApplicationTracker/ApplicationTracker\n","\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/ApplicationTracker/ApplicationTracker/ApplicationTracker/ApplicationTracker/.git/\n","Application.ipynb  DeepSort_YOLO.ipynb\tPothole\n","If you don’t see your notebook above, adjust the path below:\n","[master (root-commit) 940ac61] Initial commit: Add application tracking notebook\n"," 1 file changed, 1 insertion(+)\n"," create mode 100644 Application.ipynb\n","To https://github.com/andrew-dragoslavic/ApplicationTracker.git\n"," \u001b[31m! [rejected]       \u001b[m master -> master (fetch first)\n","\u001b[31merror: failed to push some refs to 'https://github.com/andrew-dragoslavic/ApplicationTracker.git'\n","\u001b[m\u001b[33mhint: Updates were rejected because the remote contains work that you do\u001b[m\n","\u001b[33mhint: not have locally. This is usually caused by another repository pushing\u001b[m\n","\u001b[33mhint: to the same ref. You may want to first integrate the remote changes\u001b[m\n","\u001b[33mhint: (e.g., 'git pull ...') before pushing again.\u001b[m\n","\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"]}]},{"cell_type":"code","source":["!pip install transformers torch accelerate bitsandbytes bs4"],"metadata":{"id":"NTgj2MURkoYf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import imaplib\n","import email\n","from email import policy\n","from bs4 import BeautifulSoup\n","import re\n","from datetime import datetime\n","from transformers import pipeline\n","import torch\n","from transformers import BitsAndBytesConfig\n","from google.colab import userdata"],"metadata":{"id":"By2tFQlj9Bp9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["HF_TOKEN = userdata.get('HF_TOKEN')\n","\n","model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\"\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","grok_pipeline = pipeline(\n","    \"text-generation\",\n","    model=model_name,  # GPU\n","    torch_dtype=torch.float16,\n","    model_kwargs={\"quantization_config\": quantization_config},\n","    token=HF_TOKEN  # Optional, only if you’re logged in\n",")"],"metadata":{"id":"aOQdPhYJ9ZVz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fetch_emails(server, username, password, start_date, mailbox=\"INBOX\", num_emails=None):\n","    \"\"\"Fetch raw emails from the Primary section of the Gmail inbox starting from a specific date.\"\"\"\n","    mail = imaplib.IMAP4_SSL(server)\n","    mail.login(username, password)\n","    mail.select(mailbox)\n","\n","    if isinstance(start_date, datetime):\n","        start_date = start_date.strftime(\"%d-%b-%Y\")\n","    try:\n","        datetime.strptime(start_date, \"%d-%b-%Y\")\n","    except ValueError:\n","        raise ValueError(\"start_date must be in 'dd-Mon-yyyy' format, e.g., '01-Jan-2025'\")\n","\n","    print(f\"Searching with date: {start_date}\")\n","    status, messages = mail.search(None, f'SINCE {start_date}', '(X-GM-RAW \"category:primary\")')\n","    if status != \"OK\":\n","        raise Exception(f\"Failed to search emails: {messages}\")\n","\n","    email_ids = messages[0].split()\n","    print(f\"Found {len(email_ids)} email IDs\")\n","    if not email_ids:\n","        print(f\"No Primary emails found since {start_date}\")\n","        mail.logout()\n","        return []\n","\n","    if num_emails:\n","        email_ids = email_ids[-num_emails:]\n","        print(f\"Limiting to {len(email_ids)} emails\")\n","\n","    raw_emails = []\n","    for email_id in email_ids:\n","        status, msg_data = mail.fetch(email_id, \"(RFC822)\")\n","        if status != \"OK\":\n","            continue\n","        raw_email = msg_data[0][1].decode(\"utf-8\", errors=\"ignore\")\n","        raw_emails.append(raw_email)\n","\n","    mail.logout()\n","    print(f\"Fetched {len(raw_emails)} emails\")\n","    return raw_emails"],"metadata":{"id":"2nE-4odI24xj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def parse_email(raw_email):\n","    \"\"\"Parse a raw email string into sender, subject, and body with cleaned-up text.\"\"\"\n","    msg = email.message_from_string(raw_email, policy=policy.default)\n","    sender = msg.get(\"From\")\n","    subject = msg.get(\"Subject\")\n","    body = None\n","    if msg.is_multipart():\n","        for part in msg.walk():\n","            content_type = part.get_content_type()\n","            if content_type == \"text/plain\":\n","                body = part.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\")\n","                body = re.sub(r'\\s+', ' ', body).strip()\n","                break\n","            elif content_type == \"text/html\":\n","                html_body = part.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\")\n","                soup = BeautifulSoup(html_body, \"html.parser\")\n","                body = soup.get_text(separator=\" \")\n","                body = re.sub(r'\\s+', ' ', body).strip()\n","                break\n","    else:\n","        content_type = msg.get_content_type()\n","        if content_type == \"text/plain\":\n","            body = msg.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\")\n","            body = re.sub(r'\\s+', ' ', body).strip()\n","        elif content_type == \"text/html\":\n","            html_body = msg.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\")\n","            soup = BeautifulSoup(html_body, \"html.parser\")\n","            body = soup.get_text(separator=\" \")\n","            body = re.sub(r'\\s+', ' ', body).strip()\n","    return sender, subject, body"],"metadata":{"id":"zVG0sv2v281F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_email_with_grok(sender, subject, body):\n","    \"\"\"Use Mixtral-8x7B-Instruct to classify and summarize an email.\"\"\"\n","    prompt = (\n","    \"[INST] Determine if this email is a response to a job application I sent to the specified company. \"\n","    \"If it is, return the result in this exact format: 'Company: [company], Job Position: [position], Status: [status]', \"\n","    \"where Status must be one of these four options only: 'received', 'interviewing', 'rejected', or 'job offer'. \"\n","    \"If it is not, return exactly this: 'Not a job application email'. \"\n","    \"Note: Emails from companies like Glassdoor or LinkedIn about new job postings are not responses to job applications; classify those as 'Not a job application email'. \"\n","    \"Do not include any additional explanation or deviation from these formats.\\n\\n\"\n","    f\"Sender: {sender}\\nSubject: {subject}\\nBody: {body} [/INST]\"\n","    )\n","\n","    try:\n","        result = grok_pipeline(prompt, max_new_tokens=1000, do_sample=False, temperature=0.5)[0][\"generated_text\"]\n","        # Extract response after the prompt\n","        response = result[len(prompt):].strip()\n","        return response\n","    except Exception as e:\n","        print(f\"Processing error: {e}\")\n","        return \"Error processing email\""],"metadata":{"id":"u9Mks87C3AMP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')  # Download the sentence tokenizer\n","nltk.download('punkt_tab')\n","\n","import pandas as pd\n","\n","def extract_final_output(output):\n","    # Split on </think> and take the last part (the actual output)\n","    parts = output.split('</think>')\n","    if len(parts) > 1:\n","        final_output = parts[-1].strip()  # Get text after </think>, remove leading/trailing whitespace\n","    else:\n","        final_output = output.strip()  # Fallback if no </think> tag\n","\n","    print(\"Full Response:\", output)\n","    print(\"Extracted Output:\", final_output)\n","\n","    # Parse the final output\n","    if final_output.startswith(\"Company:\"):\n","        match = re.match(r\"Company: (.+?), Job Position: (.+?), Status: (.+)\", final_output)\n","        if match:\n","            company, position, status = match.groups()\n","            return {\"Company\": company, \"Job Position\": position, \"Status\": status}\n","    elif final_output == \"Not a job application email\":\n","        return None\n","    return None  # Default for unexpected format\n"],"metadata":{"id":"AajBpEO9uSyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install nltk pandas openpyxl"],"metadata":{"id":"G04RqZU6wjJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["username = userdata.get('email')\n","password = userdata.get('password')\n","\n","raw_emails = fetch_emails(\n","    server=\"imap.gmail.com\",\n","    username=username,\n","    password=password,\n","    start_date=\"20-Mar-2025\",\n","    num_emails=None\n",")\n","\n","all_data = []\n","for i, raw_email in enumerate(raw_emails, 1):\n","    sender, subject, body = parse_email(raw_email)\n","    print(f\"Email {i}:\")\n","    print(f\"Sender: {sender}\")\n","    print(f\"Subject: {subject}\")\n","    print(f\"Body: {body}\")\n","\n","    result = process_email_with_grok(sender, subject, body)\n","    # Treat result as a single string, not an iterable\n","    extracted = extract_final_output(result)\n","    if extracted is not None:\n","        all_data.append(extracted)\n","\n","    print(\"Extracted Data (this email):\", extracted)\n","    print(\"-\" * 50)\n","\n","# Create DataFrame from all data\n","df = pd.DataFrame(all_data)\n","print(\"Final DataFrame:\\n\", df)\n","\n","# excel_filename = \"job_applications.xlsx\"\n","# df.to_excel(excel_filename, index=False)\n","\n","# # Download\n","# from google.colab import files\n","# files.download(excel_filename)"],"metadata":{"id":"0qbXMpAg3Cmp"},"execution_count":null,"outputs":[]}]}